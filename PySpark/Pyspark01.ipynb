{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6702,"status":"ok","timestamp":1646195883003,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07991490287572730826"},"user_tz":-330},"id":"5vVN4fmY6scV"},"outputs":[{"ename":"Py4JJavaError","evalue":"An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x2e55dd0c) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x2e55dd0c\r\n\tat org.apache.spark.storage.StorageUtils$.<init>(StorageUtils.scala:213)\r\n\tat org.apache.spark.storage.StorageUtils$.<clinit>(StorageUtils.scala)\r\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:110)\r\n\tat org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:348)\r\n\tat org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:287)\r\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:336)\r\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:191)\r\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:277)\r\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:460)\r\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\r\n\tat java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:67)\r\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\r\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:483)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:238)\r\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\r\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:833)\r\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)","\u001b[1;32md:\\Python\\PySpark\\Pyspark01.ipynb Cell 1\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Python/PySpark/Pyspark01.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontext\u001b[39;00m \u001b[39mimport\u001b[39;00m SparkContext\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Python/PySpark/Pyspark01.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msql\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msession\u001b[39;00m \u001b[39mimport\u001b[39;00m SparkSession\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Python/PySpark/Pyspark01.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m sc \u001b[39m=\u001b[39m SparkContext(\u001b[39m'\u001b[39;49m\u001b[39mlocal\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Python/PySpark/Pyspark01.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m spark \u001b[39m=\u001b[39m SparkSession(sc)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyspark\\context.py:146\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    144\u001b[0m SparkContext\u001b[39m.\u001b[39m_ensure_initialized(\u001b[39mself\u001b[39m, gateway\u001b[39m=\u001b[39mgateway, conf\u001b[39m=\u001b[39mconf)\n\u001b[0;32m    145\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n\u001b[0;32m    147\u001b[0m                   conf, jsc, profiler_cls)\n\u001b[0;32m    148\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     \u001b[39m# If an error occurs, clean up in order to allow future SparkContext creation:\u001b[39;00m\n\u001b[0;32m    150\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop()\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyspark\\context.py:209\u001b[0m, in \u001b[0;36mSparkContext._do_init\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menvironment[\u001b[39m\"\u001b[39m\u001b[39mPYTHONHASHSEED\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mPYTHONHASHSEED\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    208\u001b[0m \u001b[39m# Create the Java SparkContext through Py4J\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jsc \u001b[39m=\u001b[39m jsc \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize_context(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conf\u001b[39m.\u001b[39;49m_jconf)\n\u001b[0;32m    210\u001b[0m \u001b[39m# Reset the SparkConf to the one actually used by the SparkContext in JVM.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_conf \u001b[39m=\u001b[39m SparkConf(_jconf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jsc\u001b[39m.\u001b[39msc()\u001b[39m.\u001b[39mconf())\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pyspark\\context.py:329\u001b[0m, in \u001b[0;36mSparkContext._initialize_context\u001b[1;34m(self, jconf)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_initialize_context\u001b[39m(\u001b[39mself\u001b[39m, jconf):\n\u001b[0;32m    326\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[39m    Initialize SparkContext in function to allow subclass specific initialization\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jvm\u001b[39m.\u001b[39;49mJavaSparkContext(jconf)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\py4j\\java_gateway.py:1585\u001b[0m, in \u001b[0;36mJavaClass.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1579\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCONSTRUCTOR_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1580\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_command_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1581\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1582\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1584\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1585\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1586\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gateway_client, \u001b[39mNone\u001b[39;49;00m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fqn)\n\u001b[0;32m   1588\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1589\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n","\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext.\n: java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x2e55dd0c) cannot access class sun.nio.ch.DirectBuffer (in module java.base) because module java.base does not export sun.nio.ch to unnamed module @0x2e55dd0c\r\n\tat org.apache.spark.storage.StorageUtils$.<init>(StorageUtils.scala:213)\r\n\tat org.apache.spark.storage.StorageUtils$.<clinit>(StorageUtils.scala)\r\n\tat org.apache.spark.storage.BlockManagerMasterEndpoint.<init>(BlockManagerMasterEndpoint.scala:110)\r\n\tat org.apache.spark.SparkEnv$.$anonfun$create$9(SparkEnv.scala:348)\r\n\tat org.apache.spark.SparkEnv$.registerOrLookupEndpoint$1(SparkEnv.scala:287)\r\n\tat org.apache.spark.SparkEnv$.create(SparkEnv.scala:336)\r\n\tat org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:191)\r\n\tat org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:277)\r\n\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:460)\r\n\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\r\n\tat java.base/jdk.internal.reflect.DirectConstructorHandleAccessor.newInstance(DirectConstructorHandleAccessor.java:67)\r\n\tat java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499)\r\n\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:483)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:238)\r\n\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\r\n\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:833)\r\n"]}],"source":["import pyspark as ps\n","from pyspark.context import SparkContext\n","from pyspark.sql.session import SparkSession\n","sc = SparkContext('local')\n","spark = SparkSession(sc)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1646195883004,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07991490287572730826"},"user_tz":-330},"id":"iu6Nf7RS5a-c"},"outputs":[],"source":["#Create DataFrame with Examples"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1646195883004,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07991490287572730826"},"user_tz":-330},"id":"bIzjGr3M5qEt"},"outputs":[],"source":["columns = [\"language\",\"users_count\"]\n","data = [(\"Java\", \"20000\"), (\"Python\", \"100000\"), (\"Scala\", \"3000\")]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":412,"status":"ok","timestamp":1646196341708,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07991490287572730826"},"user_tz":-330},"id":"yLhHys4E6Cpq","outputId":"cd5c36fb-ff96-496d-b15f-83c15da843a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------+------+\n","|    _1|    _2|\n","+------+------+\n","|  Java| 20000|\n","|Python|100000|\n","| Scala|  3000|\n","+------+------+\n","\n"]}],"source":["df1 = spark.createDataFrame(data)\n","df1.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":652,"status":"ok","timestamp":1646196344111,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07991490287572730826"},"user_tz":-330},"id":"4BheY5kU8PG5","outputId":"60846c11-123a-4113-8256-5b65fbd18663"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+-----------+\n","|language|users_count|\n","+--------+-----------+\n","|    Java|      20000|\n","|  Python|     100000|\n","|   Scala|       3000|\n","+--------+-----------+\n","\n"]}],"source":["df1 = df1.toDF(*columns)\n","df1.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1095,"status":"ok","timestamp":1646196450953,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07991490287572730826"},"user_tz":-330},"id":"Pxu-1u6F8Z9d","outputId":"f5cddd62-8291-4fb9-8e45-5e5d4685516d"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------+-----------+---------------+-----------------+--------------------+-----------------+--------------------+-----------------+-----------------+------------+--------------------+---------------------+---------------+----------------+---------------+-----------------+--------------------+-----------------+--------------------+-----------------+-----------------+------------+--------------------+---------------------+---------------+----------------+---------------+-----------------+-------------+-----------------+--------------------+-----------------+-----------------+------------+----------------+---------------------+---------------+----------------+---------------+-----------------+-------------+-----------------+--------------------+-----------------+-----------------+------------+----------------+---------------------+---------------+----------------+\n","|patientid|speciesname|2018_hospitalid|2018_membershipid|       2018_planname|2018_isplanmember|2018_isrenewalmember|2018_cancelreason|2018_cohortvisits|2018_revenue|    2018_servicelist|2018_serviceusedcount|2018_useddental|2018_usedvaccine|2019_hospitalid|2019_membershipid|       2019_planname|2019_isplanmember|2019_isrenewalmember|2019_cancelreason|2019_cohortvisits|2019_revenue|    2019_servicelist|2019_serviceusedcount|2019_useddental|2019_usedvaccine|2020_hospitalid|2020_membershipid|2020_planname|2020_isplanmember|2020_isrenewalmember|2020_cancelreason|2020_cohortvisits|2020_revenue|2020_servicelist|2020_serviceusedcount|2020_useddental|2020_usedvaccine|2021_hospitalid|2021_membershipid|2021_planname|2021_isplanmember|2021_isrenewalmember|2021_cancelreason|2021_cohortvisits|2021_revenue|2021_servicelist|2021_serviceusedcount|2021_useddental|2021_usedvaccine|\n","+---------+-----------+---------------+-----------------+--------------------+-----------------+--------------------+-----------------+-----------------+------------+--------------------+---------------------+---------------+----------------+---------------+-----------------+--------------------+-----------------+--------------------+-----------------+-----------------+------------+--------------------+---------------------+---------------+----------------+---------------+-----------------+-------------+-----------------+--------------------+-----------------+-----------------+------------+----------------+---------------------+---------------+----------------+---------------+-----------------+-------------+-----------------+--------------------+-----------------+-----------------+------------+----------------+---------------------+---------------+----------------+\n","|  1404361|        Cat|            153|         14023807|Senior Paws Plus ...|             true|                true|             null|                4|     2275.88|Feline Senior Wel...|                    7|           true|           false|            153|         49435715|Senior Paws Plus ...|             true|                true|  Pet passed away|                3|     3320.88|Canine/Feline Sen...|                    8|          false|           false|           null|             null|         null|             null|                null|             null|             null|        null|            null|                 null|           null|            null|           null|             null|         null|             null|                null|             null|             null|        null|            null|                 null|           null|            null|\n","+---------+-----------+---------------+-----------------+--------------------+-----------------+--------------------+-----------------+-----------------+------------+--------------------+---------------------+---------------+----------------+---------------+-----------------+--------------------+-----------------+--------------------+-----------------+-----------------+------------+--------------------+---------------------+---------------+----------------+---------------+-----------------+-------------+-----------------+--------------------+-----------------+-----------------+------------+----------------+---------------------+---------------+----------------+---------------+-----------------+-------------+-----------------+--------------------+-----------------+-----------------+------------+----------------+---------------------+---------------+----------------+\n","only showing top 1 row\n","\n"]}],"source":["#Creating DataFrame from CSV\n","df2 = spark.read.csv(\"vca.csv\", header=True, inferSchema=True)\n","df2.show(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1646196882667,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07991490287572730826"},"user_tz":-330},"id":"EPwS_Wv080TS","outputId":"72ffdd4e-e6de-4cab-9ae6-6c08b8ab6763"},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- firstname: string (nullable = true)\n"," |-- middlename: string (nullable = true)\n"," |-- lastname: string (nullable = true)\n","\n"]}],"source":["#Create Schema\n","from pyspark.sql.types import StructType,StructField, StringType\n","schema = StructType([\n","  StructField('firstname', StringType(), True),\n","  StructField('middlename', StringType(), True),\n","  StructField('lastname', StringType(), True)\n","  ])\n","#Creates Empty RDD\n","emptyRDD = spark.sparkContext.emptyRDD()\n","#Create empty DataFrame from empty RDD\n","df = spark.createDataFrame(emptyRDD,schema)\n","df.printSchema()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":402,"status":"ok","timestamp":1646196880246,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07991490287572730826"},"user_tz":-330},"id":"bWYiMiYQ-W5v","outputId":"4349c182-1197-4c35-f14e-a115b522a795"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------+----------+--------+\n","|firstname|middlename|lastname|\n","+---------+----------+--------+\n","+---------+----------+--------+\n","\n"]}],"source":["df.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":403,"status":"ok","timestamp":1646196988880,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07991490287572730826"},"user_tz":-330},"id":"58gTdmoH99cl","outputId":"e7253ee8-e580-4d4f-bd5d-1d01b0df7220"},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- firstname: string (nullable = true)\n"," |-- middlename: string (nullable = true)\n"," |-- lastname: string (nullable = true)\n","\n"]}],"source":["#Convert empty RDD to Dataframe\n","df1 = emptyRDD.toDF(schema)\n","df1.printSchema()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":671,"status":"ok","timestamp":1646197048521,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07991490287572730826"},"user_tz":-330},"id":"ITKmsVVA-NyZ","outputId":"57c4c16c-69ad-40de-c80f-0caa17273413"},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- firstname: string (nullable = true)\n"," |-- middlename: string (nullable = true)\n"," |-- lastname: string (nullable = true)\n","\n","+---------+----------+--------+\n","|firstname|middlename|lastname|\n","+---------+----------+--------+\n","+---------+----------+--------+\n","\n"]}],"source":["#Create empty DataFrame directly.\n","df2 = spark.createDataFrame([], schema)\n","df2.printSchema()\n","df2.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":400,"status":"ok","timestamp":1646197123383,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07991490287572730826"},"user_tz":-330},"id":"HoUogB2E-aCN","outputId":"d0cb63f2-218b-4675-a6d8-ed3d8b52d729"},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n","\n","++\n","||\n","++\n","++\n","\n"]}],"source":["#Create empty DatFrame with no schema (no columns)\n","df3 = spark.createDataFrame([], StructType([]))\n","df3.printSchema()\n","df3.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":396,"status":"ok","timestamp":1646197274442,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07991490287572730826"},"user_tz":-330},"id":"7JEQJtGD_cEJ","outputId":"c1e2f242-bc2a-4f05-eea3-5679f5c2fb64"},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- firstname: string (nullable = true)\n","\n","+---------+\n","|firstname|\n","+---------+\n","+---------+\n","\n"]}],"source":["#Create empty DatFrame with schema (columns)\n","from pyspark.sql.types import StructType,StructField, StringType\n","df3 = spark.createDataFrame([], StructType([StructField('firstname', StringType(), True)]))\n","df3.printSchema()\n","df3.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":681,"status":"ok","timestamp":1646197616505,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07991490287572730826"},"user_tz":-330},"id":"zxOaF-L4AKIg","outputId":"eb526998-af24-48d0-a69c-6fcdb80a74e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- first_name: string (nullable = true)\n"," |-- middle_name: string (nullable = true)\n"," |-- last_name: string (nullable = true)\n"," |-- dob: string (nullable = true)\n"," |-- gender: string (nullable = true)\n"," |-- salary: long (nullable = true)\n","\n","+----------+-----------+---------+-----+------+------+\n","|first_name|middle_name|last_name|  dob|gender|salary|\n","+----------+-----------+---------+-----+------+------+\n","|     James|           |    Smith|36636|     M| 60000|\n","|   Michael|       Rose|         |40288|     M| 70000|\n","|    Robert|           | Williams|42114|      |400000|\n","|     Maria|       Anne|    Jones|39192|     F|500000|\n","|       Jen|       Mary|    Brown|     |     F|     0|\n","+----------+-----------+---------+-----+------+------+\n","\n"]}],"source":["data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",60000),\n","        (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",70000),\n","        (\"Robert\",\"\",\"Williams\",\"42114\",\"\",400000),\n","        (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",500000),\n","        (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",0)]\n","\n","columns = [\"first_name\",\"middle_name\",\"last_name\",\"dob\",\"gender\",\"salary\"]\n","pysparkDF = spark.createDataFrame(data = data, schema = columns)\n","pysparkDF.printSchema()\n","pysparkDF.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":675,"status":"ok","timestamp":1646197661497,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07991490287572730826"},"user_tz":-330},"id":"vg-gW1yAA-WL","outputId":"edfaf9d6-5e35-4c27-d55d-2379c4097aed"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_name</th>\n","      <th>middle_name</th>\n","      <th>last_name</th>\n","      <th>dob</th>\n","      <th>gender</th>\n","      <th>salary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>James</td>\n","      <td></td>\n","      <td>Smith</td>\n","      <td>36636</td>\n","      <td>M</td>\n","      <td>60000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Michael</td>\n","      <td>Rose</td>\n","      <td></td>\n","      <td>40288</td>\n","      <td>M</td>\n","      <td>70000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Robert</td>\n","      <td></td>\n","      <td>Williams</td>\n","      <td>42114</td>\n","      <td></td>\n","      <td>400000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Maria</td>\n","      <td>Anne</td>\n","      <td>Jones</td>\n","      <td>39192</td>\n","      <td>F</td>\n","      <td>500000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Jen</td>\n","      <td>Mary</td>\n","      <td>Brown</td>\n","      <td></td>\n","      <td>F</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  first_name middle_name last_name    dob gender  salary\n","0      James                 Smith  36636      M   60000\n","1    Michael        Rose            40288      M   70000\n","2     Robert              Williams  42114         400000\n","3      Maria        Anne     Jones  39192      F  500000\n","4        Jen        Mary     Brown             F       0"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["pandasDF = pysparkDF.toPandas()\n","pandasDF"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1646198010851,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07991490287572730826"},"user_tz":-330},"id":"nF8HSaqWBrXR","outputId":"f5b5afdb-7c84-4b2b-d5d4-9e7471e0e4be"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----+--------------------+\n","|Seqno|               Quote|\n","+-----+--------------------+\n","|    1|Be the change tha...|\n","|    2|Everyone thinks o...|\n","|    3|The purpose of ou...|\n","|    4|            Be cool.|\n","+-----+--------------------+\n","\n"]}],"source":["#def show(self, n=20, truncate=True, vertical=False):\n","columns = [\"Seqno\",\"Quote\"]\n","data = [(\"1\", \"Be the change that you wish to see in the world\"),\n","    (\"2\", \"Everyone thinks of changing the world, but no one thinks of changing himself.\"),\n","    (\"3\", \"The purpose of our lives is to be happy.\"),\n","    (\"4\", \"Be cool.\")]\n","\n","pysparkDF = spark.createDataFrame(data = data, schema = columns)\n","pysparkDF.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1646198047896,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07991490287572730826"},"user_tz":-330},"id":"dH84Jbn2CMXV","outputId":"d86c69a3-d044-4889-b164-86f145e98fdc"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----+-----------------------------------------------+\n","|Seqno|                                          Quote|\n","+-----+-----------------------------------------------+\n","|    1|Be the change that you wish to see in the world|\n","+-----+-----------------------------------------------+\n","only showing top 1 row\n","\n"]}],"source":["pysparkDF.show(vertical=False, truncate=50, n=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1646198657595,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07991490287572730826"},"user_tz":-330},"id":"-prczvs8EKM5"},"outputs":[],"source":["from pyspark.sql import functions as F "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":682,"status":"ok","timestamp":1646199291251,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07991490287572730826"},"user_tz":-330},"id":"t75QlRcZFgz-","outputId":"6059ff4e-e90e-4341-806d-b7afd7d2499f"},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------+------+\n","|name.fname|gender|\n","+----------+------+\n","|     James|    23|\n","|       Ann|    40|\n","+----------+------+\n","\n","+------+\n","|gender|\n","+------+\n","|    23|\n","|    40|\n","+------+\n","\n","+------+\n","|gender|\n","+------+\n","|    23|\n","|    40|\n","+------+\n","\n","+----------+\n","|name.fname|\n","+----------+\n","|     James|\n","|       Ann|\n","+----------+\n","\n","+------+\n","|gender|\n","+------+\n","|    23|\n","|    40|\n","+------+\n","\n","+------+\n","|gender|\n","+------+\n","|    23|\n","|    40|\n","+------+\n","\n","+----------+\n","|name.fname|\n","+----------+\n","|     James|\n","|       Ann|\n","+----------+\n","\n"]}],"source":["data=[(\"James\",23),(\"Ann\",40)]\n","df=spark.createDataFrame(data).toDF(\"name.fname\",\"gender\")\n","df.show()\n","df.select(df.gender).show()\n","df.select('gender').show()\n","df.select('`name.fname`').show()\n","df.select(df['gender']).show()\n","\n","\n","#Using SQL col() function\n","from pyspark.sql.functions import col\n","df.select(col(\"gender\")).show()\n","#Accessing column name with dot (with backticks)\n","df.select(col(\"`name.fname`\")).show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1154,"status":"ok","timestamp":1646202105257,"user":{"displayName":"Himanshu Kashyap","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07991490287572730826"},"user_tz":-330},"id":"MbN500btH7Ud","outputId":"5d86f20b-5668-49c9-d773-dc4d6ea635c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------------+\n","|(col1 + col2)|\n","+-------------+\n","|          102|\n","|          203|\n","|          304|\n","+-------------+\n","\n","+-------------+\n","|(col1 - col2)|\n","+-------------+\n","|           98|\n","|          197|\n","|          296|\n","+-------------+\n","\n","+-------------+\n","|(col1 * col2)|\n","+-------------+\n","|          200|\n","|          600|\n","|         1200|\n","+-------------+\n","\n","+-----------------+\n","|    (col1 / col2)|\n","+-----------------+\n","|             50.0|\n","|66.66666666666667|\n","|             75.0|\n","+-----------------+\n","\n","+-------------+\n","|(col1 % col2)|\n","+-------------+\n","|            0|\n","|            2|\n","|            0|\n","+-------------+\n","\n","+-------------+\n","|(col2 > col3)|\n","+-------------+\n","|         true|\n","|        false|\n","|        false|\n","+-------------+\n","\n","+-------------+\n","|(col2 < col3)|\n","+-------------+\n","|        false|\n","|         true|\n","|        false|\n","+-------------+\n","\n","+-------------+\n","|(col2 = col3)|\n","+-------------+\n","|        false|\n","|        false|\n","|         true|\n","+-------------+\n","\n"]}],"source":["data=[(100,2,1),(200,3,4),(300,4,4)]\n","df=spark.createDataFrame(data).toDF(\"col1\",\"col2\",\"col3\")\n","\n","#Arthmetic operations\n","df.select(df.col1 + df.col2).show()\n","df.select(df.col1 - df.col2).show() \n","df.select(df.col1 * df.col2).show()\n","df.select(df.col1 / df.col2).show()\n","df.select(df.col1 % df.col2).show()\n","df.select(df.col2 > df.col3).show()\n","df.select(df.col2 < df.col3).show()\n","df.select(df.col2 == df.col3).show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nxkrYsZ-IJMR"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO//8xvkuWEK4u5nz8OK7B+","name":"Pyspark01.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"518071c88b4194aee059da36c8bb8c7f03edabff5e31c99a4f47aa39aa99e517"}}},"nbformat":4,"nbformat_minor":0}
